#!/usr/bin/env python3
"""
example_usage.py
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ollama_clientæ¨¡å—çš„ç¤ºä¾‹
"""

import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from ollama_client import (
    create_ollama_client, 
    load_ollama_config,
    OllamaClientError
)


def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("=== åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ ===")
    
    # 1. åŠ è½½é…ç½®
    config = load_ollama_config()
    print(f"åŠ è½½çš„é…ç½®: {config}")
    
    # 2. åˆ›å»ºå®¢æˆ·ç«¯
    client = create_ollama_client(config)
    print(f"åˆ›å»ºçš„å®¢æˆ·ç«¯: {client}")
    
    # 3. æµ‹è¯•è¿æ¥
    if client.test_connection():
        print("âœ“ OllamaæœåŠ¡è¿æ¥æ­£å¸¸")
    else:
        print("âœ— æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
        return
    
    # 4. è¿›è¡Œç¿»è¯‘
    system_prompt = "You are a professional translator. Translate the following text into natural, fluent simplified Chinese. DO NOT translate or remove any formating tags. Return ONLY the Chinese translation."
    text_to_translate = "Hello, this is a test message for translation."
    
    try:
        translated_text, context = client.translate(text_to_translate, system_prompt)
        print(f"åŸæ–‡: {text_to_translate}")
        print(f"è¯‘æ–‡: {translated_text}")
        print(f"ä¸Šä¸‹æ–‡: {context}")
    except OllamaClientError as e:
        print(f"ç¿»è¯‘å¤±è´¥: {e}")


def example_custom_config():
    """è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹"""
    print("\n=== è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹ ===")
    
    # è‡ªå®šä¹‰é…ç½®
    custom_config = {
        "url": "http://localhost:11434/api/generate",
        "model_name": "qwen3:4b-instruct-2507-q8_0",
        "temperature": 0.2,  # ç¨å¾®å¢åŠ éšæœºæ€§
        "top_p": 0.95,
        "repeat_penalty": 1.1,
        "timeout": 120,  # å‡å°‘è¶…æ—¶æ—¶é—´
        "retries": 2     # å‡å°‘é‡è¯•æ¬¡æ•°
    }
    
    print(f"è‡ªå®šä¹‰é…ç½®: {custom_config}")
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = create_ollama_client(custom_config)
    
    # æµ‹è¯•è¿æ¥
    if client.test_connection():
        print("âœ“ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿æ¥æˆåŠŸ")
    else:
        print("âœ— ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿æ¥å¤±è´¥")


def example_error_handling():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    print("\n=== é”™è¯¯å¤„ç†ç¤ºä¾‹ ===")
    
    # ä½¿ç”¨é”™è¯¯çš„URLæµ‹è¯•é”™è¯¯å¤„ç†
    bad_config = {
        "url": "http://localhost:9999/api/generate",  # é”™è¯¯çš„ç«¯å£
        "model_name": "test-model",
        "temperature": 0.1,
        "top_p": 0.9,
        "repeat_penalty": 1.2,
        "timeout": 5,  # çŸ­è¶…æ—¶
        "retries": 1   # åªé‡è¯•ä¸€æ¬¡
    }
    
    client = create_ollama_client(bad_config)
    
    try:
        result = client.test_connection()
        print(f"è¿æ¥æµ‹è¯•ç»“æœ: {result}")
    except Exception as e:
        print(f"é¢„æœŸçš„è¿æ¥é”™è¯¯: {e}")
    
    # æµ‹è¯•ç¿»è¯‘é”™è¯¯å¤„ç†
    try:
        translated_text, context = client.translate(
            "Test text", 
            "Translate to Chinese"
        )
    except OllamaClientError as e:
        print(f"é¢„æœŸçš„ç¿»è¯‘é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("Ollamaå®¢æˆ·ç«¯æ¨¡å—ä½¿ç”¨ç¤ºä¾‹\n")
    
    try:
        example_basic_usage()
        example_custom_config()
        example_error_handling()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
